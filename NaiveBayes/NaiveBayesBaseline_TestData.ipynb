{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Food Review Classification Model using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from Dave's file directory\n",
    "df = pd.read_csv('~/.kaggle/datasets/snap/amazon-fine-food-reviews/Reviews.csv', encoding='utf8')\n",
    "df_imdb = pd.read_csv('../data_prep/imdb_1_5.csv', encoding='utf8')\n",
    "df_yelp = pd.read_csv('../data_prep/yelp_1_5.csv', encoding='utf8')\n",
    "df_beer = pd.read_csv('../data_prep/rate_beer_binary_medium.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For development, just use 10 rows for simplicity and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "def convertTo1or5(score):\n",
    "    if score == 2:\n",
    "        return 1\n",
    "    elif score == 4:\n",
    "        return 5\n",
    "    else:\n",
    "        return score\n",
    "\n",
    "# Reduce training dataset to 1s and 5s\n",
    "df_binary = df[(df.Score == 1) | (df.Score == 2) | (df.Score == 4) | (df.Score == 5)]\n",
    "df_binary.reset_index(inplace=True)\n",
    "\n",
    "df_binary['Score'] = df_binary['Score'].apply(lambda score: convertTo1or5(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_binary['Tokens'] = df_binary['Text'].apply(lambda text: word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tokens, X_test_tokens, y_train, y_test = train_test_split(df_binary['Text'], df_binary['Score'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to vectors for input to BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_tokens)\n",
    "X_test = vectorizer.transform(X_test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Bernoulli Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 87.43%\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB test size:  (1980,)\n",
      "Accuracy on IMDB test set: 50.61%\n"
     ]
    }
   ],
   "source": [
    "# The below code will use the Amazon trained Naive Bayes classifer and predict IMDB reviews\n",
    "\n",
    "# Convert text into tokens\n",
    "df_imdb['Tokens'] = df_imdb['Text'].apply(lambda text: word_tokenize(text))\n",
    "\n",
    "# Ensure train and test matrices are in same vector shapes for BernoulliNB model\n",
    "X_imdb_train_tokens, X_imdb_test_tokens, y_imdb_train, y_imdb_test = train_test_split(df_imdb['Text'], df_imdb['Score'], test_size=.99)\n",
    "imdb_test = vectorizer.transform(X_imdb_test_tokens)\n",
    "\n",
    "# Calculate predictions of test data\n",
    "y_imdb_pred = nb.predict(imdb_test)\n",
    "imdb_accuracy = accuracy_score(y_imdb_test,y_imdb_pred)\n",
    "print(\"IMDB test size: \", y_imdb_pred.shape)\n",
    "print(\"Accuracy on IMDB test set: {:.02%}\".format(imdb_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp test size:  (1425,)\n",
      "Accuracy on yelp test set: 58.11%\n"
     ]
    }
   ],
   "source": [
    "# The below code will use the Amazon trained Naive Bayes classifer and predict yelp reviews\n",
    "\n",
    "# Convert text into tokens\n",
    "df_yelp['Tokens'] = df_yelp['Text'].apply(lambda text: word_tokenize(text))\n",
    "\n",
    "# Ensure train and test matrices are in same vector shapes for BernoulliNB model\n",
    "X_yelp_train_tokens, X_yelp_test_tokens, y_yelp_train, y_yelp_test = train_test_split(df_yelp['Text'], df_yelp['Score'], test_size=.99)\n",
    "yelp_test = vectorizer.transform(X_yelp_test_tokens)\n",
    "\n",
    "# Calculate predictions of test data\n",
    "y_yelp_pred = nb.predict(yelp_test)\n",
    "yelp_accuracy = accuracy_score(y_yelp_test,y_yelp_pred)\n",
    "print(\"Yelp test size: \", y_yelp_pred.shape)\n",
    "print(\"Accuracy on yelp test set: {:.02%}\".format(yelp_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RateBeer test size:  (70714,)\n",
      "Accuracy on RateBeer test set: 58.97%\n"
     ]
    }
   ],
   "source": [
    "# The below code will use the Amazon trained Naive Bayes classifer and predict RateBeer reviews\n",
    "\n",
    "# Convert text into tokens\n",
    "df_beer['Tokens'] = df_beer['Text'].apply(lambda text: word_tokenize(text))\n",
    "\n",
    "# Ensure train and test matrices are in same vector shapes for BernoulliNB model\n",
    "X_beer_train_tokens, X_beer_test_tokens, y_beer_train, y_beer_test = train_test_split(df_beer['Text'], df_beer['Score'], test_size=.99)\n",
    "beer_test = vectorizer.transform(X_beer_test_tokens)\n",
    "\n",
    "# Calculate predictions of test data\n",
    "y_beer_pred = nb.predict(beer_test)\n",
    "beer_accuracy = accuracy_score(y_beer_test,y_beer_pred)\n",
    "print(\"RateBeer test size: \", y_beer_pred.shape)\n",
    "print(\"Accuracy on RateBeer test set: {:.02%}\".format(beer_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
