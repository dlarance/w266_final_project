{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Bag of Words for Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dal7p/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'w266_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f85735397aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Helper libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mw266_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_embed_viz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreeviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mw266_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpatched_numpy_io\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Code for this assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'w266_common'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os, sys, re, json, time, datetime, shutil\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.8\"))\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary, tf_embed_viz, treeviz\n",
    "from w266_common import patched_numpy_io\n",
    "\n",
    "# Helper libraries for Dave's instance\n",
    "from w266_common import utils, vocabulary, tf_embed_viz, treeviz\n",
    "from w266_common import patched_numpy_io\n",
    "\n",
    "# Code for this assignment\n",
    "\n",
    "import models\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os.path\n",
    "wordsList = np.load(os.path.join(str(Path.home()), '.kaggle/wordvectors/pretrained_glove/wordsList.npy'))\n",
    "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
    "wordVectors = np.load(os.path.join(str(Path.home()), '.kaggle/wordvectors/pretrained_glove/wordVectors.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('~/.kaggle/datasets/snap/amazon-fine-food-reviews/Reviews.csv', encoding='utf8')\n",
    "review_df = review_df.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce size for development\n",
    "numReviews = 100\n",
    "review_df = review_df.loc[0:numReviews-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['Tokens'] = review_df['Text'].apply(lambda text: word_tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Dev, Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with 60%, , Dev: 10%, Test: 30%\n",
    "train_percent = 0.6\n",
    "dev_percent = 0.3\n",
    "test_percent = 1 - (train_percent+dev_percent)\n",
    "\n",
    "# Get indicies of the rows in the dataframe for training and testing\n",
    "train_lower_index = 0\n",
    "train_upper_index = train_lower_index + round(len(review_df)*train_percent)\n",
    "dev_lower_index   = train_upper_index+1\n",
    "dev_upper_index   = dev_lower_index + round(len(review_df)*dev_percent)\n",
    "test_lower_index  = dev_upper_index+1\n",
    "test_upper_index  = len(review_df)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 250  # Determined by EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids = np.zeros([review_df.shape[0], maxSeqLength], dtype=np.int32)\n",
    "word_ids_ns = np.zeros([review_df.shape[0]], dtype=np.int32)\n",
    "word_ids_labels = np.zeros([review_df.shape[0]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence_index, row in review_df.iterrows():\n",
    "    \n",
    "    word_index = 0\n",
    "    \n",
    "    for word in row['Tokens']:\n",
    "\n",
    "        try:\n",
    "            word_ids[sentence_index][word_index] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            word_ids[sentence_index][word_index] = 399999 #Vector for unkown words\n",
    "        \n",
    "        word_index = word_index + 1\n",
    "\n",
    "        if word_index == maxSeqLength:\n",
    "            break\n",
    "\n",
    "    word_ids_ns[sentence_index] = word_index\n",
    "\n",
    "    if row['Score'] >= 3:\n",
    "        word_ids_labels[sentence_index] = 1\n",
    "    else:\n",
    "        word_ids_labels[sentence_index] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split(lower_idx, upper_idx):\n",
    "    return word_ids[lower_idx:upper_idx], word_ids_ns[lower_idx:upper_idx], word_ids_labels[lower_idx:upper_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_ns, train_y = Split(train_lower_index, train_upper_index)\n",
    "dev_x,   dev_ns,   dev_y   = Split(dev_lower_index, dev_upper_index)\n",
    "test_x,  test_ns,  test_y  = Split(test_lower_index, test_upper_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models; reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model hyperparameters as used by model_fn\n",
    "model_params = dict(V=len(wordsList),\n",
    "                    embed_dim=50,\n",
    "                    hidden_dims=[25],\n",
    "                    num_classes=2,      # 2 for binary classifier\n",
    "                    encoder_type='bow',\n",
    "                    lr=0.1,\n",
    "                    optimizer='adagrad',\n",
    "                    beta=0.01,\n",
    "                    dropout_rate=0.1)  # fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify training schedule\n",
    "train_params = dict(batch_size=32,\n",
    "                    total_epochs=20,\n",
    "                    eval_every=2)  # fill this in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/tmp/tf_bow_sst_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "if os.path.isdir(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "#ds.vocab.write_projector_config(checkpoint_dir, \"Encoder/Embedding_Layer/W_embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.estimator.Estimator(model_fn=models.classifier_model_fn,\n",
    "                               params=model_params,\n",
    "                               model_dir=checkpoint_dir)\n",
    "\n",
    "print(\"\\nTo view training (once it starts), run:\\n\")\n",
    "print(\"    tensorboard --logdir='{:s}' --port 6006\".format(checkpoint_dir))\n",
    "print(\"\\nThen in your browser, open: http://localhost:6006\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = patched_numpy_io.numpy_input_fn(\n",
    "                    x={\"ids\": train_x, \"ns\": train_ns},\n",
    "                    y=train_y,\n",
    "                    batch_size=train_params['batch_size'], \n",
    "                    num_epochs=train_params['eval_every'],\n",
    "                    shuffle=True,\n",
    "                    seed=42)\n",
    "\n",
    "dev_input_fn = patched_numpy_io.numpy_input_fn(\n",
    "                    x={\"ids\": dev_x, \"ns\": dev_ns},\n",
    "                    y=dev_y,\n",
    "                    batch_size=128,\n",
    "                    num_epochs=1,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(train_params['total_epochs'] // train_params['eval_every']):\n",
    "    model.train(input_fn=train_input_fn)\n",
    "    model.evaluate(input_fn=dev_input_fn, name=\"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = patched_numpy_io.numpy_input_fn(\n",
    "                    x={\"ids\": test_x, \"ns\": test_ns},\n",
    "                    y=test_y,\n",
    "                    batch_size=128,\n",
    "                    num_epochs=1,\n",
    "                    shuffle=False)\n",
    "\n",
    "eval_metrics = model.evaluate(input_fn=test_input_fn, name=\"test\")\n",
    "print(\"Accuracy on test set: {:.02%}\".format(eval_metrics['accuracy']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
